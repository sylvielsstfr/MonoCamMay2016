{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ccdproc Example Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk you through an example reduction of optical CCD data using ``ccdproc``.\n",
    "\n",
    "The data is available at this link (about 500MB): http://physics.mnstate.edu/craig/2013-07-03-r-only.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Required software:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make sure you have this software installed before you begin (in addition to the usual scipy, numpy):\n",
    "\n",
    "+ [astropy](http://astropy.org) v 0.4 or higher (install with: ``pip install astropy`` in a terminal/command window)\n",
    "+ [ccdproc](http://ccdproc.readthedocs.org) v 0.1.1 or higher (install with: ``pip install ccdproc`` in a terminal/command window)\n",
    "+ [msumastro](http://msumastro.readthedocs.org) v 0.5 or higher (install with : ``pip install msumastro`` in a terminal/command window)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports you will always need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from astropy.modeling import models\n",
    "from astropy import units as u\n",
    "from astropy import nddata\n",
    "from astropy.io import fits\n",
    "\n",
    "import ccdproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional import 1 (it is used in this notebook): bottleneck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In numpy 1.8.1 and lower, median combination of masked arrays can be very slow when combining a small number of images with a large number of pixels. ``bottleneck`` is a temporary workaround until numpy 1.9 is released.\n",
    "\n",
    "However, **installing ``bottleneck`` requires a compiler**, so you can use numpy instead if you want.\n",
    "\n",
    "To use numpy instead of bottleneck, simply **comment out the import below**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bottleneck as bn  # numpy's masked median is slow...really slow (in version 1.8.1 and lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'1.0.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccdproc.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional import 2 (it is used in this notebook): msumastro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though most of the ``msumastro`` package is about massaging the headers of images taken from a particular small observatory, there is one useful bit for working with a set of FITS images in a directly.\n",
    "\n",
    "**There is no easy way to remove this import**, but it is a pure python package, so ``pip install msumastro`` should work on any platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from msumastro import ImageFileCollection, TableTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I know you can't do correlated errors....\n",
    "nddata.conf.warn_unsupported_correlated = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Set some properties of the instrument that took these images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gain = 1.47 * u.electron / u.adu\n",
    "readnoise = 29 * u.electron  # wish it wasn't, but it really seems to be..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define a few convenience functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these aare really optional, but some are pretty convenient. They are provided in part to illustrate how one can combine the basic ``ccdproc`` commands into something more like a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Subtract overscan and trim images in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def oscan_and_trim(image_list):\n",
    "    \"\"\"\n",
    "    Remove overscan and trim a list of images. The original list is replaced by a list of images\n",
    "    with the changes applied.\n",
    "    \"\"\"\n",
    "    for idx, img in enumerate(image_list):\n",
    "        oscan = ccdproc.subtract_overscan(img, img[:, 3075:3079], add_keyword={'oscan_sub': True, 'calstat': 'O'}, model=models.Polynomial1D(1))\n",
    "        image_list[idx] = ccdproc.trim_image(oscan[:, :3073], add_keyword={'trimmed': True, 'calstat': 'OT'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Calculate fast medians (only really needed until numpy 1.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     A bottleneck-based replacement for ma.median for a *single* array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained above, in numpy 1.8.1 and lower the masked median of a stack of images is very slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bn_median(masked_array, axis=None):\n",
    "    \"\"\"\n",
    "    Perform fast median on masked array\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    masked_array : `numpy.ma.masked_array`\n",
    "        Array of which to find the median.\n",
    "    \n",
    "    axis : int, optional\n",
    "        Axis along which to perform the median. Default is to find the median of\n",
    "        the flattened array.\n",
    "    \"\"\"\n",
    "    data = masked_array.filled(fill_value=np.NaN)\n",
    "    med = bn.nanmedian(data, axis=axis)\n",
    "    # construct a masked array result, setting the mask from any NaN entries\n",
    "    return np.ma.array(med, mask=np.isnan(med))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bottleneck-based replacement for a stack (i.e. list) of masked arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By \"stack\" I mean a group of images, e.g. darks of the same exposure, for which the appropriate baseline image for identifying bad pixels is a median image (rather than a median or mean of the whole stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avg_over_images(masked_arr, axis=0):\n",
    "    \"\"\"\n",
    "    Calculate average pixel value along specified axis\n",
    "    \"\"\"\n",
    "    return ma.mean(masked_arr, axis=axis)\n",
    "\n",
    "def med_over_images(masked_arr, axis=0):\n",
    "    \"\"\"\n",
    "    Calculate median pixel value along specified axis\n",
    "    \n",
    "    Uses bottleneck.nanmedian for speed\n",
    "    \"\"\"\n",
    "    \n",
    "    dat = masked_arr.data.copy()\n",
    "    dat[masked_arr.mask] = np.NaN\n",
    "    return bn.nanmedian(dat, axis=axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. A little function for displaying image statistics...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...which is useful for determining scale when displaying an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imstats = lambda dat: (dat.min(), dat.max(), dat.mean(), dat.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``ImageFileCollection`` is part of the `msumastro` package -- it constructs a table of the FITS keyword values for the files in a directory and provides methods for iterating over the files. The docs for the package are a bit of a mess, but are at http://msum-astro.readthedocs.org (or skip right to the useful bit, the [API for ImageFileCollection](http://msum-astro.readthedocs.org/en/latest/api/msumastro.image_collection.ImageFileCollection.html#msumastro.image_collection.ImageFileCollection)).\n",
    "\n",
    "\n",
    "The code below reads through the headers of all of the FITS files in the ``data_dir``, creates an ``astropy`` ``Table`` of the keywords, and provides a few methods for iterating over the files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modify ``data_dir`` to point at your copy of the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ImageFileCollection.hdus of <msumastro.image_collection.ImageFileCollection object at 0x113884510>>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = './2013-07-03-r-only/'\n",
    "\n",
    "images = ImageFileCollection(data_dir, keywords='*')\n",
    "images.hdus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Make a master bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is straightforward because all we do is:\n",
    "\n",
    "+ subtract overscan\n",
    "+ trim\n",
    "+ combine using average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. First, load the data as a list of ``CCDData`` objects.\n",
    "\n",
    "If you don't need to modify the metadata you could use ``ccdproc.CCDData.from_hdu(hdu)`` to create the ``CCDData`` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fname =  ./2013-07-03-r-only/flood-flat-001bias.fit\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unit for CCDData must be specified",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3a813af9c462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'fname = '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mccd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mccdproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCCDData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#ccd=ccdproc.fits_ccddata_read(fname)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbias_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mccd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dagoret-campagnesylvie/anaconda/envs/pyastrophys/lib/python2.7/site-packages/astropy/nddata/mixins/ndio.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mio_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dagoret-campagnesylvie/anaconda/envs/pyastrophys/lib/python2.7/site-packages/astropy/io/registry.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dagoret-campagnesylvie/anaconda/envs/pyastrophys/lib/python2.7/site-packages/ccdproc/ccddata.pyc\u001b[0m in \u001b[0;36mfits_ccddata_reader\u001b[0;34m(filename, hdu, unit, hdu_uncertainty, hdu_mask, hdu_flags, **kwd)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0mwcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwcs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         ccd_data = CCDData(hdus[hdu].data, meta=hdr, unit=use_unit,\n\u001b[0;32m--> 604\u001b[0;31m                            mask=mask, uncertainty=uncertainty, wcs=wcs)\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mccd_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dagoret-campagnesylvie/anaconda/envs/pyastrophys/lib/python2.7/site-packages/ccdproc/ccddata.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwd)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCCDData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unit for CCDData must be specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unit for CCDData must be specified"
     ]
    }
   ],
   "source": [
    "bias_list = []\n",
    "for hdu, fname in images.hdus(imagetyp='bias', return_fname=True):\n",
    "    meta = hdu.header\n",
    "    print 'fname = ',fname\n",
    "    meta['filename'] = fname\n",
    "    ccd=ccdproc.CCDData.read(fname)\n",
    "    #ccd=ccdproc.fits_ccddata_read(fname)\n",
    "    bias_list.append(ccd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Subtract overscan and trim using convenience function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oscan_and_trim(bias_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Combine biases using average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biases = ccdproc.Combiner(bias_list)\n",
    "master_bias = biases.average_combine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Make a pretty picture...\n",
    "\n",
    "Because why wouldn't you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bias_min, bias_max, bias_mean, bias_std = imstats(np.asarray(master_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(master_bias, vmax=bias_mean + 4*bias_std, vmin=bias_mean - 4*bias_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Make some master darks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complicated than the bias frames because we will:\n",
    "\n",
    "+ subtract overscan\n",
    "+ trim\n",
    "+ sigma clip the image stack to remove outliers\n",
    "+ combine using median\n",
    "\n",
    "This will **be done twice**, once for each for darks with 15 sec and 30 sec exposures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Define convenince function (optional, justification below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll make two, one a 30 second exposure for calibrating science frames, the other a 15 second exposure for calibrating a flat field.\n",
    "\n",
    "Since I'm going to be making two, and I have no desire to write the code twice, I'll write a short function to do the job.\n",
    "\n",
    "These darks are **not** bias-subtracted since their exposures match that of the images they will be used to calibrate. Because of this, they cannot be scaled to other exposure times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def overscan_trim_and_sigma_clip_median(image_list, clip_baseline_func=med_over_images):\n",
    "    \"\"\"\n",
    "    Combine a list of images using median\n",
    "    \n",
    "    This function does several steps:\n",
    "    \n",
    "    1. Subtract overscan\n",
    "    2. Trim image\n",
    "    3. sigma clip image using a median of the unclipped stack as the baseline\n",
    "    4. combine the images on the list using median\n",
    "    \n",
    "    ** It modifies the images in the input list. **\n",
    "    \"\"\"\n",
    "    oscan_and_trim(image_list)\n",
    "    combo = ccdproc.Combiner(image_list)\n",
    "    combo.sigma_clipping(func=clip_baseline_func)\n",
    "    return combo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Make CCDData objects for darks and reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation below is a little complicated because the reduction is written as a loop over two exposures. The *body* of the loop is where the reduction happends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exposures = [15, 30]\n",
    "master_darks = {}\n",
    "combiners = {}\n",
    "for exposure in exposures:\n",
    "    # make list of darks with this exposure time\n",
    "    a_list = []\n",
    "    for dark, fname in images.hdus(imagetyp='dark', exptime=exposure, return_fname=True):\n",
    "        meta = dark.header\n",
    "        meta['filename'] = fname\n",
    "        a_list.append(ccdproc.CCDData(data=dark.data, meta=meta, unit=\"adu\"))\n",
    "\n",
    "    # get the exposure time as it appears in the fits file for use as a dictionary key\n",
    "    exposure_time_in_fits_file = a_list[0].header['exptime']\n",
    "    \n",
    "    # make a combiner for sigma clipping and median combine\n",
    "    a_combiner = overscan_trim_and_sigma_clip_median(a_list)\n",
    "    combiners[exposure_time_in_fits_file] = a_combiner\n",
    "    master_darks[exposure_time_in_fits_file] = a_combiner.median_combine(median_func=bn_median)\n",
    "\n",
    "    # set the exposure time in the master -- right now combiner doesn't attempt to combine meta\n",
    "    master_darks[exposure_time_in_fits_file].header['exptime'] = exposure_time_in_fits_file\n",
    "    print \"For exposure {} seconds there are {} bad pixels in the master.\".format(exposure_time_in_fits_file,\n",
    "                                                                                  master_darks[exposure_time_in_fits_file].mask.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Display a reduced image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_min, d_max, d_mean, d_std = imstats(np.asarray(master_darks[30.0]))\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(master_darks[30.0], vmax=d_mean + 4*d_std, vmin=d_mean - 4*d_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Make some flats now, R band only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This adds two more complications compared to the darks: subtracting darks and normalizing before combining.\n",
    "\n",
    "The full set of steps will be:\n",
    "\n",
    "+ Subtract overscan\n",
    "+ Trim\n",
    "+ Subtract dark (which includes bias, so no scaling)\n",
    "+ Sigmal clip to remove outliers\n",
    "+ Combine using mean, normalizing mean of each image to the same value\n",
    "+ Use the gain to scale the flat from adu to electrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Read the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flats_r = []\n",
    "for flat, fname in images.hdus(imagetyp='flat', filter='R', return_fname=True):\n",
    "    meta = flat.header\n",
    "    meta['filename'] = fname\n",
    "    flats_r.append(ccdproc.CCDData(data=flat.data, meta=meta, unit=\"adu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Calibrate the flats by subtracting dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oscan_and_trim(flats_r)\n",
    "for flat in flats_r:\n",
    "    flat_exposure = flat.header['exptime']\n",
    "    master_dark = master_darks[flat_exposure]\n",
    "    flat = ccdproc.subtract_dark(flat, master_dark, exposure_time='exptime', exposure_unit=u.second,\n",
    "                              add_keyword={'calib': 'subtracted dark'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. sigma clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_combiner = ccdproc.Combiner(flats_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_combiner.sigma_clipping(func=med_over_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. define function for normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``ccdproc`` tries to be flexible about how you can scale data during combination. That flexibility means you have to define a function to be used for scaling each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this function will divide each array by its average before combining\n",
    "# so that each array has an average of 1 after scaling (but before combining)\n",
    "scaling_func = lambda arr: 1/np.ma.average(arr)\n",
    "flat_combiner.scaling = scaling_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_flat_r = flat_combiner.median_combine(median_func=bn_median)\n",
    "master_flat_r.header = flats_r[0].meta  # kludge -- combiner does not try to combine metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. R-band flat, calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_min, f_max, f_mean, f_std = imstats(np.asarray(master_flat_r))\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(master_flat_r, vmin=f_mean-5*f_std, vmax=f_mean+5*f_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Gain-correct the flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_flat_r_electron = ccdproc.gain_correct(master_flat_r, gain=gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Calibrate some images of stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are images of the Landolt field SA112-SF1, roughly 20' x 30'\n",
    "\n",
    "We'll do these steps:\n",
    "\n",
    "+ Subtract overscan\n",
    "+ Trim\n",
    "+ ~~Remove cosmic rays~~ (coming soon!)\n",
    "+ Subtract dark (we have darks who exposure match this science image, so no scaling)\n",
    "+ Divide by flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Read the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "star_list = []\n",
    "for star, fname in images.hdus(imagetyp='light', filter='R', return_fname=True):\n",
    "    meta = star.header\n",
    "    meta['filename'] = fname\n",
    "    star_list.append(ccdproc.CCDData(data=star.data, meta=meta, unit=\"adu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Subtract overscan and trim..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oscan_and_trim(star_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. ~~Remove cosmic rays~~ -- coming soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was effectively handled by sigma clipping in the case of darks and flats. Sigma clipping in this case would remove the bright things (like stars), so we'll use one of the cosmic ray cleaning functions instead.\n",
    "\n",
    "To check where cosmic rays were found, save the masks before running the cosmic ray cleaner then compare to mask after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_masks = []\n",
    "for star in star_list:\n",
    "    try:\n",
    "        original_masks.append(star.mask.copy())\n",
    "    except AttributeError:\n",
    "        original_masks.append(None)\n",
    "print original_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: cosmic ray cleaning is coming soon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#star_list_cr_cleaned = []\n",
    "#for star in star_list:\n",
    "#    star_no_nan = star.copy()\n",
    "#    star_no_nan.data[np.isnan(star.data)] = 1e21\n",
    "    #cr_cleaned = ccdp.cosmicray_clean(star, 9, ccdp.cosmicray_median, crargs=(11,), background=ccdp.background_variance_box,\n",
    "    #                                  bargs=(25,), rbox=11)\n",
    "    #star_list_cr_cleaned.append(cr_cleaned)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for star in star_list:\n",
    "#    try:\n",
    "#        print \"Found {} cosmic rays in {}\".format(star.mask.sum(), star.meta['filename'])\n",
    "#    except AttributeError:\n",
    "#        print \"Found 0 cosmic rays in {}\".format(star.meta['filename'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample image with cosmic rays marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#an_image = star_list_cr_cleaned[0]\n",
    "#print imstats(an_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imshow(an_image, vmin=9-3*27, vmax=9+10*27)\n",
    "#ycr, xcr = where(an_image.mask)\n",
    "#plot(xcr, ycr, 'o', fillstyle='none', markeredgecolor='red', markersize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Calibrate science images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Currently based on the non-cosmic ray cleaned images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "star_calibrated = []\n",
    "mask_info = lambda name, num: \"Pixels masked after {}: {}\".format(name, num) \n",
    "mask_num = lambda mask: 0 if mask is None else mask.sum()\n",
    "for star in star_list:\n",
    "    star_exp = star.meta['exptime']\n",
    "    star_dark = ccdproc.subtract_dark(star, master_darks[star_exp], exposure_time='exptime', exposure_unit=u.second)    \n",
    "    star_gain = ccdproc.gain_correct(star_dark, gain=gain)\n",
    "    star_flat = ccdproc.flat_correct(star_gain, master_flat_r_electron)\n",
    "    star_calibrated.append(star_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Display sample calibrated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "star_0 = star_calibrated[0]\n",
    "star_0 = ccdproc.create_variance(star_0, readnoise=readnoise)\n",
    "ma_star_0 = np.ma.array(star_0.data, mask=star_0.mask)\n",
    "mean_star_0 =  np.ma.mean(ma_star_0)\n",
    "std_star_0 = np.ma.std(ma_star_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(ma_star_0, vmin=mean_star_0 - 5*std_star_0, vmax=mean_star_0+10*std_star_0, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same image, uncalibrated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try and match the image above, it is plotted about its own mean, with upper/lower limit set to those in amge above, downscaled by gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std_dev = mean_star_0/gain.value\n",
    "star_0_uncal = star_list[0]\n",
    "star_0_uncal = ccdproc.create_variance(star_0_uncal, gain=gain, readnoise=readnoise)\n",
    "mean_0_uncal = star_0.data.mean()\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(star_list[0].data, vmin=mean_0_uncal-5*std_dev, vmax=mean_0_uncal+10*std_dev, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epilogue: Create a multi-extension FITS file to hold this reduced image, uncertainty, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is nothing approaching a standard as to how a dataset like a masked array should be stored. this is most definitely *NOT* intended as any sort of standard...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_hdu_list = star_0.to_hdu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_hdu_list[0].header['bunit'] = u.photon.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uncertainty_header = fits.Header()\n",
    "uncertainty_header['bunit'] = u.photon.to_string()\n",
    "uncertainty_header['name'] = 'uncertainty'\n",
    "uncertainty_hdu = fits.ImageHDU(data=star_0.uncertainty.array, header=uncertainty_header, name='uncertainty')\n",
    "image_hdu_list.append(uncertainty_hdu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask_header = fits.Header()\n",
    "mask_header.add_comment('TRUE indicates the data is INVALID')\n",
    "# FITS isn't fond of boolean images -- convert it to 32 bit integers, nonzero indicates True\n",
    "mask_array = np.zeros_like(star_0.mask, dtype=np.int32)\n",
    "mask_array[star_0.mask] = 1\n",
    "mask_hdu = fits.ImageHDU(data=mask_array, header=mask_header, name='mask')\n",
    "image_hdu_list.append(mask_hdu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "fname_base = os.path.basename(star_0.header['filename'])\n",
    "image_hdu_list.writeto('reduced' + fname_base)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
