{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MONOCAMCCDRed a package to do CCD reduction for MONOCAM/LSST\n",
    "===============================================================================================================\n",
    "\n",
    "This is the notebook to do the whole CCD reduction pipeline using the **CCDPROC** python package from astropy astronomical tools.\n",
    "We are considering raw data images that comes from fits file which header does not full conform to standard.\n",
    "Some keywords are missing.\n",
    "\n",
    "- Creation date Friday 2016 June 3rd\n",
    "- Author Sylvie Dagoret-Campagne\n",
    "- affiliation : LAL/IN2P3/CNRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is inspired and adapted from the Matt Craig notebook available here\n",
    "http://nbviewer.jupyter.org/gist/mwcraig/06060d789cc298bbb08e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Required softwares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make sure you have this software installed before you begin (in addition to the usual scipy, numpy):\n",
    "\n",
    "+ [astropy](http://astropy.org) v 0.4 or higher (install with: ``pip install astropy`` in a terminal/command window)\n",
    "+ [ccdproc](http://ccdproc.readthedocs.org) v 0.1.1 or higher (install with: ``pip install ccdproc`` in a terminal/command window)\n",
    "+ [msumastro](http://msumastro.readthedocs.org) v 0.5 or higher (install with : ``pip install msumastro`` in a terminal/command window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Main Packages imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccdproc version 1.0.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from astropy.modeling import models\n",
    "from astropy import units as u\n",
    "from astropy import nddata\n",
    "from astropy.io import fits\n",
    "\n",
    "import ccdproc\n",
    "print 'ccdproc version',ccdproc.__version__\n",
    "\n",
    "from astropy.modeling import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats  \n",
    "import os\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottleneck version 1.0.0\n"
     ]
    }
   ],
   "source": [
    "import bottleneck as bn  # numpy's masked median is slow...really slow (in version 1.8.1 and lower)\n",
    "print 'bottleneck version',bn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from msumastro import ImageFileCollection, TableTree\n",
    "# I know you can't do correlated errors....\n",
    "nddata.conf.warn_unsupported_correlated = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard date format for the analysis : 2016-06-03 19:46:33.228110\n",
      "fits date format for the analysis :  2016-06-03T19:46:33\n"
     ]
    }
   ],
   "source": [
    "now=datetime.utcnow()  # choose UTC time\n",
    "datestr=str(now)\n",
    "print 'standard date format for the analysis :',datestr\n",
    "#  want the following format '2016-05-10T11:55:27.267'\n",
    "date_of_analysis=now.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "print 'fits date format for the analysis : ',date_of_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Set some properties of the instrument that took these images\n",
    "\n",
    "- MONOCAM, one of the 200 CCD plate of LSST camera.\n",
    "- This CCD is 4Kx4K readout by 16 amplifiers\n",
    "\n",
    "Eeach fits file contains a primary header plus the 16 images\n",
    "\n",
    "- 16 images of size 544 x 2048 pixels\n",
    "corresponding of :\n",
    "- 8 columns of 544 pixels : 8 x 544 = 4352 pixels \n",
    "- 2 raws of 2048 pixels : 2 x 2048 = 4096 pixels\n",
    "\n",
    "There is an excess of 4352-4096= 256 pixels along the columns.\n",
    "It is possible there is 32 overscan slots.\n",
    "\n",
    "\n",
    "A pre-look to the flats data using ds9 or python script allowed me to guess what are the Trim section and the Bias section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_OF_CHAN_AMPL=16    # 16 images in each of the fits file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define a few convenience functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these are really optional, but some are pretty convenient. They are provided in part to illustrate how one can combine the basic ``ccdproc`` commands into something more like a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Subtract overscan and trim images in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oscan_and_trim(image_list):\n",
    "    \"\"\"\n",
    "    Remove overscan and trim a list of images. The original list is replaced by a list of images\n",
    "    with the changes applied.\n",
    "    \"\"\"\n",
    "    for idx, img in enumerate(image_list):\n",
    "        oscan = ccdproc.subtract_overscan(img,overscan=img[:,521:544], add_keyword={'oscan_sub': True, 'calstat': 'O'}, model=models.Polynomial1D(1))\n",
    "        image_list[idx] = ccdproc.trim_image(oscan[:,10:521], add_keyword={'trimmed': True, 'calstat': 'OT'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Calculate fast medians (only really needed until numpy 1.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     A bottleneck-based replacement for ma.median for a *single* array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained above, in numpy 1.8.1 and lower the masked median of a stack of images is very slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bn_median(masked_array, axis=None):\n",
    "    \"\"\"\n",
    "    Perform fast median on masked array\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    masked_array : `numpy.ma.masked_array`\n",
    "        Array of which to find the median.\n",
    "    \n",
    "    axis : int, optional\n",
    "        Axis along which to perform the median. Default is to find the median of\n",
    "        the flattened array.\n",
    "    \"\"\"\n",
    "    data = masked_array.filled(fill_value=np.NaN)\n",
    "    med = bn.nanmedian(data, axis=axis)\n",
    "    # construct a masked array result, setting the mask from any NaN entries\n",
    "    return np.ma.array(med, mask=np.isnan(med))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bottleneck-based replacement for a stack (i.e. list) of masked arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By \"stack\" I mean a group of images, e.g. darks of the same exposure, for which the appropriate baseline image for identifying bad pixels is a median image (rather than a median or mean of the whole stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_over_images(masked_arr, axis=0):\n",
    "    \"\"\"\n",
    "    Calculate average pixel value along specified axis\n",
    "    \"\"\"\n",
    "    return ma.mean(masked_arr, axis=axis)\n",
    "\n",
    "def med_over_images(masked_arr, axis=0):\n",
    "    \"\"\"\n",
    "    Calculate median pixel value along specified axis\n",
    "    \n",
    "    Uses bottleneck.nanmedian for speed\n",
    "    \"\"\"\n",
    "    \n",
    "    dat = masked_arr.data.copy()\n",
    "    dat[masked_arr.mask] = np.NaN\n",
    "    return bn.nanmedian(dat, axis=axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little function for displaying image statistics....\n",
    "\n",
    "..which is useful for determining scale when displaying an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imstats = lambda dat: (dat.min(), dat.max(), dat.mean(), dat.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To make the list of biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BuildFilelist(path,name,ext='.fits',start=1,stop=99):\n",
    "    '''\n",
    "    Make the list of filenames required by ccdproc\n",
    "    \n",
    "    input:\n",
    "       path : path of files\n",
    "       name : common root of bias filenames\n",
    "       ext  : extension of filenames\n",
    "       start,stop : indexes of files\n",
    "    output:\n",
    "       full filename list\n",
    "    '''\n",
    "    filelist = []\n",
    "    for num in range(start,stop+1,1):\n",
    "        strnum=biasnumberstr= '{0:02d}'.format(num)  # python >= 2.6\n",
    "        filename=name+strnum+ext\n",
    "        fullfilename=os.path.join(path,filename)\n",
    "        filelist.append(fullfilename)\n",
    "    return filelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.) Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path='/Users/dagoret-campagnesylvie/iraf/MonoCamMay2016/20160509'\n",
    "ext_filename='.fits'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1) The biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_biasfilename='bias_'\n",
    "bias_startnum=1\n",
    "bias_stopnum=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawbias_list=BuildFilelist(path,root_biasfilename,start=bias_startnum,stop=bias_stopnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NB_OF_BIAS=len(rawbias_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. First, load the data as a list of ``CCDData`` objects.\n",
    "\n",
    "If you don't need to modify the metadata you could use ``ccdproc.CCDData.from_hdu(hdu)`` to create the ``CCDData`` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allrawbias = []\n",
    "for chan in range(1,NB_OF_CHAN_AMPL+1,1):\n",
    "    ccd_chan = [ ccdproc.CCDData.read(image_file, hdu=chan,unit=\"adu\") for image_file in rawbias_list ]\n",
    "    allrawbias.append(ccd_chan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Subtract overscan and trim using convenience function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for chan in range(NB_OF_CHAN_AMPL):\n",
    "    oscan_and_trim(allrawbias[chan])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Combine biases using average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "masterbias_list=[]\n",
    "for chan in range(NB_OF_CHAN_AMPL):\n",
    "    biases = ccdproc.Combiner(allrawbias[chan])\n",
    "    master_bias = biases.average_combine()\n",
    "    masterbias_list.append(master_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Make a pretty picture...\n",
    "\n",
    "Because why wouldn't you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel bias_min, bias_max, bias_mean, bias_std\n",
      "0 -0.926953778281 16.3574736904 0.538108686844 0.314870975147\n",
      "1 -0.639385815501 35.4088702041 0.835044293876 0.377250931763\n",
      "2 -0.913389727384 38.8144456782 0.580852228386 0.311788112246\n",
      "3 -0.890469859412 45.6265212098 0.430237770077 0.325260488652\n",
      "4 -1.11275323819 21.4632614112 0.406213044674 0.343524256608\n",
      "5 -0.963451023399 32.0665673545 0.380810888376 0.307063493072\n",
      "6 -0.837847425025 55.5501415345 0.512449337236 0.307441787621\n",
      "7 -0.893613608593 51.3755929349 0.498104392728 0.313701611048\n",
      "8 -1.43605580358 30.6485440915 0.583935905825 0.411604744699\n",
      "9 -1.33418415968 24.6522832673 0.339367110557 0.393719203177\n",
      "10 -1.50468322554 684.242805897 0.437289507698 1.38351603217\n",
      "11 -1.33862449849 68.966238715 0.615655893042 0.473045631306\n",
      "12 -1.48307837304 76.331293991 0.354877731516 0.419033305126\n",
      "13 -1.2807210196 75.5247703881 0.75011139443 0.407416808246\n",
      "14 -2.42971475843 48.0989244106 0.631909913791 0.693127033129\n",
      "15 -1.68870998362 168.559410764 0.573173487453 0.48789613583\n"
     ]
    }
   ],
   "source": [
    "print 'channel bias_min, bias_max, bias_mean, bias_std'\n",
    "for chan in range(NB_OF_CHAN_AMPL):\n",
    "    bias_min, bias_max, bias_mean, bias_std = imstats(np.asarray(masterbias_list[chan]))\n",
    "    print chan,bias_min, bias_max, bias_mean, bias_std\n",
    "    \n",
    "    #plt.figure(figsize=(5, 5))\n",
    "    #plt.imshow(masterbias_list[chan], vmax=bias_mean + 4*bias_std, vmin=bias_mean - 4*bias_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) The darks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_darkfilename='dark_'\n",
    "dark_startnum=1\n",
    "dark_stopnum=63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawdark_list=BuildFilelist(path,root_darkfilename,start=dark_startnum,stop=dark_stopnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allrawdark = []\n",
    "for chan in range(1,NB_OF_CHAN_AMPL+1,1):\n",
    "    ccd_chan = [ ccdproc.CCDData.read(image_file, hdu=chan,unit=\"adu\") for image_file in rawdark_list ]\n",
    "    allrawdark.append(ccd_chan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3) The sky flats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 544)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allrawbias[0][0].data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Process bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Subtract overscan and trim using convenience function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: Keyword name 'oscan_sub' is greater than 8 characters or contains characters not allowed by the FITS standard; a HIERARCH card will be created. [astropy.io.fits.card]\n"
     ]
    }
   ],
   "source": [
    "for chan in range(NB_OF_CHAN_AMPL):\n",
    "    oscan_and_trim(allrawbias[chan])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Combine biases using average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ccdproc.ccddata.CCDData"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from astropy import units as u\n",
    "arr1 = ccdproc.CCDData(np.ones([100, 100]), unit=u.adu)\n",
    "type(arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_scan = ccdproc.subtract_overscan(arr1, overscan=arr1[:, 90:100])\n",
    "assert (no_scan.data == 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_scan = ccdproc.subtract_overscan(arr1, fits_section='[91:100, :]')\n",
    "assert (no_scan.data == 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_keyword={'oscan_sub': True, 'calstat': 'O'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(add_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
